{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextRCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwoPaNahQ6U8S4E0JmheUF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yixish/NLPLearning/blob/master/TextRCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dxfv_KaEI4H",
        "outputId": "dffd2f58-529b-4627-9886-2b82c18675e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzNcJHV5EVeg",
        "outputId": "a3c107ee-8dad-4b2c-8a8a-fc8b5241a02f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct 28 07:31:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9KNtDf3Ed_u"
      },
      "source": [
        "import collections\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchtext.vocab as Vocab\n",
        "import torch.utils.data as Data\n",
        "import torch.nn.functional as F\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JVTcKc0Ej8E",
        "outputId": "aa30080c-7b68-4941-d5e3-2322f60c9f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import pandas as pd\n",
        "def read_hotel():\n",
        "    train_df =  pd.read_csv('/content/gdrive/My Drive/dataset/Hotel_rating/train.csv');\n",
        "    \n",
        "    keys =  list(train_df['review'].values)\n",
        "    vals =  list(train_df['rating'].values)\n",
        "    data = []\n",
        "    for i in range(len(keys)):\n",
        "        data.append([keys[i],vals[i]-1])\n",
        "    data_len = len(data)\n",
        "    return data[:int(data_len*0.8)],data[int(data_len*0.2):]\n",
        "\n",
        "train_data,test_data= read_hotel()\n",
        "\n",
        "# 打印训练数据中的前五个sample\n",
        "for sample in train_data[:5]:\n",
        "    print(sample[1], '\\t', sample[0][:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 \t good place stay check rainforest biobay vieques/cu\n",
            "4 \t great firstly did n't enjoy hong kong, 3 days quit\n",
            "3 \t clean convenient hotel catedral ideally located ke\n",
            "2 \t transport good class high excellent communications\n",
            "3 \t stay happy la quinta, used stay travelodge street \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX_Sa26OEl22",
        "outputId": "04bd2710-91bb-43e8-c0ca-c88edea6d549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def get_tokenized(data):\n",
        "    '''\n",
        "    @params:\n",
        "        data: 数据的列表，列表中的每个元素为 [文本字符串，0/1标签] 二元组\n",
        "    @return: 切分词后的文本的列表，列表中的每个元素为切分后的词序列\n",
        "    '''\n",
        "    def tokenizer(text):\n",
        "        return [tok.lower() for tok in text.split(' ')]\n",
        "    \n",
        "    return [tokenizer(review) for review, _ in data]\n",
        "\n",
        "def get_vocab(data):\n",
        "    '''\n",
        "    @params:\n",
        "        data: 同上\n",
        "    @return: 数据集上的词典，Vocab 的实例（freqs, stoi, itos）\n",
        "    '''\n",
        "    tokenized_data = get_tokenized(data)\n",
        "    counter = collections.Counter([tk for st in tokenized_data for tk in st])\n",
        "    return Vocab.Vocab(counter, min_freq=5)\n",
        "\n",
        "vocab = get_vocab(train_data)\n",
        "print('# words in vocab:', len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# words in vocab: 14914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVktADZaEqeD"
      },
      "source": [
        "max_l = 500  # 将每条评论通过截断或者补0，使得长度变成500\n",
        "\n",
        "def preprocess(data, vocab):\n",
        "    '''\n",
        "    @params:\n",
        "        data: 同上，原始的读入数据\n",
        "        vocab: 训练集上生成的词典\n",
        "    @return:\n",
        "        features: 单词下标序列，形状为 (n, max_l) 的整数张量\n",
        "        labels: 情感标签，形状为 (n,) 的0/1整数张量\n",
        "    '''\n",
        " \n",
        "    def pad(x):\n",
        "        return x[:max_l] if len(x) > max_l else x + [0] * (max_l - len(x))\n",
        " \n",
        "    tokenized_data = get_tokenized(data)\n",
        "    features = torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
        "    labels = torch.tensor([score for _, score in data])\n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-JoJ9SEEuXi",
        "outputId": "a868240f-495e-4653-b6e7-bf9ff0636859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_set = Data.TensorDataset(*preprocess(train_data, vocab))\n",
        "test_set = Data.TensorDataset(*preprocess(test_data, vocab))\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "train_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\n",
        "test_iter = Data.DataLoader(test_set, batch_size)\n",
        "\n",
        "for X, y in train_iter:\n",
        "    print('X', X.shape, 'y', y.shape)\n",
        "    break\n",
        "print('#batches:', len(train_iter))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X torch.Size([64, 100]) y torch.Size([64])\n",
            "#batches: 205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHLWlNjGEznA"
      },
      "source": [
        "class TextRCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab,embedding_dim, output_dim, hidden_size, num_layers, bidirectional, dropout):\n",
        "        super(TextRCNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        # self.embedding = nn.Embedding.from_pretrained(\n",
        "        #     pretrained_embeddings, freeze=False)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        self.W2 = nn.Linear(2 * hidden_size + embedding_dim, hidden_size * 2)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        text = x.T\n",
        "        # text: [seq_len, batch size]\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # embedded: [seq_len, batch size, emb dim]\n",
        "\n",
        "        outputs, _ = self.rnn(embedded)\n",
        "        # outputs: [seq_len， batch_size, hidden_size * bidirectional]\n",
        "\n",
        "        outputs = outputs.permute(1, 0, 2)\n",
        "        # outputs: [batch_size, seq_len, hidden_size * bidirectional]\n",
        "\n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        # embeded: [batch_size, seq_len, embeding_dim]\n",
        "\n",
        "        x = torch.cat((outputs, embedded), 2)\n",
        "        # x: [batch_size, seq_len, embdding_dim + hidden_size * bidirectional]\n",
        "\n",
        "        y2 = torch.tanh(self.W2(x)).permute(0, 2, 1)\n",
        "        # y2: [batch_size, hidden_size * bidirectional, seq_len]\n",
        "\n",
        "        y3 = F.max_pool1d(y2, y2.size()[2]).squeeze(2)\n",
        "        # y3: [batch_size, hidden_size * bidirectional]\n",
        "\n",
        "        return self.fc(y3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeKaKyS_E4Wk"
      },
      "source": [
        "embed_size, num_hiddens, num_layers = 100, 100, 2\n",
        "out_dim = 5\n",
        "model = TextRCNN(vocab,embed_size, out_dim,num_hiddens, num_layers,True,0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1gy_1z_E5Ls",
        "outputId": "14b4ee64-2698-4814-a308-fd35760e6190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cache_dir = \"/content/gdrive/My Drive/dataset/GloVe6B\"\n",
        "glove_vocab = Vocab.GloVe(name='6B', dim=100, cache=cache_dir)\n",
        "\n",
        "def load_pretrained_embedding(words, pretrained_vocab):\n",
        "    '''\n",
        "    @params:\n",
        "        words: 需要加载词向量的词语列表，以 itos (index to string) 的词典形式给出\n",
        "        pretrained_vocab: 预训练词向量\n",
        "    @return:\n",
        "        embed: 加载到的词向量\n",
        "    '''\n",
        "    embed = torch.zeros(len(words), pretrained_vocab.vectors[0].shape[0]) # 初始化为0\n",
        "    oov_count = 0 # out of vocabulary\n",
        "    for i, word in enumerate(words):\n",
        "        try:\n",
        "            idx = pretrained_vocab.stoi[word]\n",
        "            embed[i, :] = pretrained_vocab.vectors[idx]\n",
        "        except KeyError:\n",
        "            oov_count += 1\n",
        "    if oov_count > 0:\n",
        "        print(\"There are %d oov words.\" % oov_count)\n",
        "    return embed\n",
        "\n",
        "model.embedding.weight.data.copy_(load_pretrained_embedding(vocab.itos, glove_vocab))\n",
        "model.embedding.weight.requires_grad = False # 直接加载预训练好的, 所以不需要更新它"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 4367 oov words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gOoErIpFBq8"
      },
      "source": [
        "def evaluate_accuracy(data_iter, net, device=None):\n",
        "    if device is None and isinstance(net, torch.nn.Module):\n",
        "        device = list(net.parameters())[0].device \n",
        "    acc_sum, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            if isinstance(net, torch.nn.Module):\n",
        "                net.eval()\n",
        "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
        "                net.train()\n",
        "            else:\n",
        "                if('is_training' in net.__code__.co_varnames):\n",
        "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
        "                else:\n",
        "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
        "            n += y.shape[0]\n",
        "    return acc_sum / n\n",
        "\n",
        "def train(train_iter, test_iter, net, loss, optimizer, device, num_epochs):\n",
        "    net = net.to(device)\n",
        "    print(\"training on \", device)\n",
        "    batch_count = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        for X, y in train_iter:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            y_hat = net(X)\n",
        "            l = loss(y_hat, y) \n",
        "            optimizer.zero_grad()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            train_l_sum += l.cpu().item()\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
        "            n += y.shape[0]\n",
        "            batch_count += 1\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\n",
        "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nn-XM8oFGOc",
        "outputId": "67e524c2-58a0-4cf4-fc21-958250cd3ef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "lr, num_epochs = 0.01, 10\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "train(train_iter, test_iter, model, loss, optimizer, device, num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on  cuda\n",
            "epoch 1, loss 1.1483, train acc 0.498, test acc 0.576, time 6.5 sec\n",
            "epoch 2, loss 0.5040, train acc 0.558, test acc 0.615, time 6.4 sec\n",
            "epoch 3, loss 0.3292, train acc 0.567, test acc 0.625, time 6.4 sec\n",
            "epoch 4, loss 0.2409, train acc 0.578, test acc 0.597, time 6.4 sec\n",
            "epoch 5, loss 0.1931, train acc 0.580, test acc 0.614, time 6.4 sec\n",
            "epoch 6, loss 0.1584, train acc 0.586, test acc 0.620, time 6.4 sec\n",
            "epoch 7, loss 0.1367, train acc 0.584, test acc 0.633, time 6.4 sec\n",
            "epoch 8, loss 0.1194, train acc 0.584, test acc 0.616, time 6.4 sec\n",
            "epoch 9, loss 0.1071, train acc 0.578, test acc 0.604, time 6.3 sec\n",
            "epoch 10, loss 0.0950, train acc 0.586, test acc 0.619, time 6.4 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlN6NKcgFJnm"
      },
      "source": [
        "def predict_sentiment(net, vocab, sentence):\n",
        "    '''\n",
        "    @params：\n",
        "        net: 训练好的模型\n",
        "        vocab: 在该数据集上创建的词典，用于将给定的单词序转换为单词下标的序列，从而输入模型\n",
        "        sentence: 需要分析情感的文本，以单词序列的形式给出\n",
        "    @return: 预测的结果，positive 为正面情绪文本，negative 为负面情绪文本\n",
        "    '''\n",
        "    if len(sentence)>=max_l:\n",
        "        sentence = sentence[:max_l]\n",
        "    device = list(net.parameters())[0].device # 读取模型所在的环境\n",
        "    sentence = torch.tensor([vocab.stoi[word] for word in sentence], device=device)\n",
        "    label = torch.argmax(net(sentence.view((1, -1))), dim=1)\n",
        "    return label.item()+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urNrkZDjFLej",
        "outputId": "765c4fa0-b7ea-4195-853f-97528b1590b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "test_df =  pd.read_csv('/content/gdrive/My Drive/dataset/Hotel_rating/test.csv');\n",
        "reviews =  list(test_df['review'].values)\n",
        "test_df['rating'] = test_df['review'].map(lambda x: predict_sentiment(model,vocab,x.split()))\n",
        "test_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4099.000000</td>\n",
              "      <td>4099.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2049.000000</td>\n",
              "      <td>3.982923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1183.423705</td>\n",
              "      <td>1.323734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1024.500000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2049.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3073.500000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4098.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id       rating\n",
              "count  4099.000000  4099.000000\n",
              "mean   2049.000000     3.982923\n",
              "std    1183.423705     1.323734\n",
              "min       0.000000     1.000000\n",
              "25%    1024.500000     4.000000\n",
              "50%    2049.000000     4.000000\n",
              "75%    3073.500000     5.000000\n",
              "max    4098.000000     5.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77SISQFhFMPO"
      },
      "source": [
        "test_df = test_df.drop('review',axis =1 )\n",
        "test_df.to_csv('/content/gdrive/My Drive/dataset/sub.csv', header=None,index=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBMCgXOkJ7uy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}